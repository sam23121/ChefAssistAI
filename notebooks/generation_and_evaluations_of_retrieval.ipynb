{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/Documents/projects/practice/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "import requests\n",
    "from groq import Groq\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") \n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "\n",
    "openrouter_client = OpenAI(\n",
    "  api_key = OPENROUTER_API_KEY,\n",
    "  base_url = \"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "groq_client = Groq(\n",
    "  api_key=GROQ_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean.csv')\n",
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Doro Wat',\n",
       " 'country': 'Ethiopia',\n",
       " 'ingredients': 'Chicken, onions, garlic, ginger, berbere spice mix, niter kibbeh',\n",
       " 'instructions': 'In a pot, sauté onions, garlic, and ginger in niter kibbeh until soft. Add berbere spice mix, cook for a few minutes, then add chicken. Cook until the chicken is tender.',\n",
       " 'meal_type': 'Main',\n",
       " 'spice_level': 'High',\n",
       " 'cooking_time_(minutes)': 90,\n",
       " 'vegetarian': 'No',\n",
       " 'main_cooking_method': 'Stewing',\n",
       " 'serving_temperature': 'Hot',\n",
       " 'how_to_make': 'Start by preparing niter kibbeh, a spiced clarified butter. Then sauté onions, garlic, and ginger in the niter kibbeh. Add berbere spice mix and stir for a few minutes. Add chicken pieces, cover, and cook until the chicken is thoroughly cooked.',\n",
       " 'id': 'f2ff4980-fda2-4bfe-8a05-aca63be38345'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a user of our Chief assistant application.\n",
    "Formulate 5 questions this user might ask based on a provided exercise.\n",
    "Make the questions specific to this exercise.\n",
    "The record should contain the answer to the questions, and the questions should\n",
    "be complete and not too short. Use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "\n",
    "name: {name},\n",
    "ingredients: {ingredients},\n",
    "instructions: {instructions},\n",
    "meal_type: {meal_type},\n",
    "spice_level: {spice_level},\n",
    "cooking_time_(minutes): {cooking_time_(minutes)},\n",
    "vegetarian: {vegetarian},\n",
    "main_cooking_method: {main_cooking_method},\n",
    "serving_temperature: {serving_temperature},\n",
    "how_to_make: {how_to_make}\n",
    "\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks and don't add anything else:\n",
    "\n",
    "{{\"questions\": [\"question1\", \"question2\", ..., \"question5\"]}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(**documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.1-8b-instruct:free\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"questions\": [\"What is the specific spice mix called in this recipe that adds high spice level?\", \"How long does it take to cook Doro Wat according to the instructions?\", \"Is Doro Wat suitable for vegetarians?\", \"What is the main cooking method for this Ethiopian dish?\", \"At what temperature should Doro Wat be served?\"]}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What is the specific spice mix called in this recipe that adds high spice level?',\n",
       "  'How long does it take to cook Doro Wat according to the instructions?',\n",
       "  'Is Doro Wat suitable for vegetarians?',\n",
       "  'What is the main cooking method for this Ethiopian dish?',\n",
       "  'At what temperature should Doro Wat be served?']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.1-8b-instruct:free\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [06:26<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for doc in tqdm(documents): \n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions_raw = generate_questions(doc)\n",
    "    questions = json.loads(questions_raw)\n",
    "    results[doc_id] = questions['questions']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in results.items():\n",
    "    for q in questions:\n",
    "        final_results.append((doc_id, q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f2ff4980-fda2-4bfe-8a05-aca63be38345',\n",
       " 'What is the recommended spice level for the Doro Wat dish?')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('36d849e4-35c1-4848-84e2-987fd1b33b9d',\n",
       " 'What is the recommended temperature at which Mitarashi Dango should be served?')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(final_results, columns=['id', 'question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/ground-truth-retrieval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>What is the recommended spice level for the Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>How long does it take to cook the Doro Wat dish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>Is the Doro Wat dish suitable for a vegetarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>What is the main cooking method used for the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>Should the Doro Wat dish be served hot or cold?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "1  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "2  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "3  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "4  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "\n",
       "                                            question  \n",
       "0  What is the recommended spice level for the Do...  \n",
       "1   How long does it take to cook the Doro Wat dish?  \n",
       "2  Is the Doro Wat dish suitable for a vegetarian...  \n",
       "3  What is the main cooking method used for the D...  \n",
       "4    Should the Doro Wat dish be served hot or cold?  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>Doro Wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78c8ff6c-af26-4012-a637-af925fda17f7</td>\n",
       "      <td>Injera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3437bb23-0c42-4548-9165-f31f586b968f</td>\n",
       "      <td>Sushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ec101289-7120-4818-99ec-40345acf99b8</td>\n",
       "      <td>Tacos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8395a5cd-7bd2-45f7-a19d-c4a232d02fa4</td>\n",
       "      <td>Paella</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id      name\n",
       "0  f2ff4980-fda2-4bfe-8a05-aca63be38345  Doro Wat\n",
       "1  78c8ff6c-af26-4012-a637-af925fda17f7    Injera\n",
       "2  3437bb23-0c42-4548-9165-f31f586b968f     Sushi\n",
       "3  ec101289-7120-4818-99ec-40345acf99b8     Tacos\n",
       "4  8395a5cd-7bd2-45f7-a19d-c4a232d02fa4    Paella"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"id\", \"name\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-retrieval.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>What is the recommended spice level for the Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>How long does it take to cook the Doro Wat dish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>Is the Doro Wat dish suitable for a vegetarian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>What is the main cooking method used for the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2ff4980-fda2-4bfe-8a05-aca63be38345</td>\n",
       "      <td>Should the Doro Wat dish be served hot or cold?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "1  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "2  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "3  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "4  f2ff4980-fda2-4bfe-8a05-aca63be38345   \n",
       "\n",
       "                                            question  \n",
       "0  What is the recommended spice level for the Do...  \n",
       "1   How long does it take to cook the Doro Wat dish?  \n",
       "2  Is the Doro Wat dish suitable for a vegetarian...  \n",
       "3  What is the main cooking method used for the D...  \n",
       "4    Should the Doro Wat dish be served hot or cold?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f2ff4980-fda2-4bfe-8a05-aca63be38345',\n",
       " 'question': 'What is the recommended spice level for the Doro Wat dish?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')\n",
    "ground_truth[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank]:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 166}},\n",
       " 'total_vector_count': 166}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")\n",
    "\n",
    "index_name = 'semantic-search-4'\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_documents(batch_size=10):\n",
    "    documents = []\n",
    "    total_vectors = index.describe_index_stats()['total_vector_count']\n",
    "    # print(f\"Total vectors in index: {total_vectors}\")\n",
    "    \n",
    "    random_vector = np.random.rand(384).tolist()  # Assuming 384 is the dimension of your vectors\n",
    "    \n",
    "    # Query all vectors\n",
    "    query_response = index.query(\n",
    "        vector=random_vector,\n",
    "        top_k=total_vectors,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # print(f\"Retrieved {len(query_response['matches'])} vectors\")\n",
    "    \n",
    "    for match in query_response['matches']:\n",
    "        # print(f\"Vector ID: {match.id}\")\n",
    "        # print(f\"Vector metadata: {match.metadata}\")\n",
    "        \n",
    "        if 'text' in match.metadata:\n",
    "            documents.append(match.metadata['text'])\n",
    "        else:\n",
    "            print(f\"Warning: 'text' not found in metadata for vector {match.id}\")\n",
    "    \n",
    "    # print(f\"Total documents retrieved: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "def keyword_search(query, documents, top_k=15):\n",
    "    tokenized_corpus = [doc.split() for doc in documents]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    tokenized_query = query.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    top_n = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "    return [(idx, bm25_scores[idx]) for idx in top_n]\n",
    "\n",
    "def query_pinecone(query, top_k=5):\n",
    "    xq = model.encode(query).tolist()\n",
    "    xc = index.query(vector=xq, top_k=top_k, include_metadata=True)\n",
    "    results = []\n",
    "    for match in xc.matches:\n",
    "        result = {\n",
    "            \"id\": match.id,\n",
    "            \"score\": match.score,\n",
    "            \"metadata\": match.metadata\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    # print(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hybrid_query_pinecone(query, documents, top_k=15, alpha=0.8):\n",
    "    # Vector search\n",
    "    xq = model.encode(query).tolist()\n",
    "    vector_results = index.query(vector=xq, top_k=top_k, include_metadata=True)\n",
    "    \n",
    "    # Keyword search\n",
    "    keyword_results = keyword_search(query, documents, top_k=top_k)\n",
    "    \n",
    "    # Combine results\n",
    "    combined_results = {}\n",
    "    for match in vector_results.matches:\n",
    "        combined_results[match.id] = {\n",
    "            \"id\": match.id,\n",
    "            \"vector_score\": match.score,\n",
    "            \"keyword_score\": 0,\n",
    "            \"metadata\": match.metadata\n",
    "        }\n",
    "    \n",
    "    for idx, score in keyword_results:\n",
    "        if idx in combined_results:\n",
    "            combined_results[idx][\"keyword_score\"] = score\n",
    "        else:\n",
    "            combined_results[idx] = {\n",
    "                \"id\": idx,\n",
    "                \"vector_score\": 0,\n",
    "                \"keyword_score\": score,\n",
    "                \"metadata\": None  # You might want to fetch metadata for these results\n",
    "            }\n",
    "    \n",
    "    # Calculate hybrid score\n",
    "    for result in combined_results.values():\n",
    "        result[\"hybrid_score\"] = alpha * result[\"vector_score\"] + (1 - alpha) * result[\"keyword_score\"]\n",
    "    \n",
    "    # Sort by hybrid score and return top results\n",
    "    sorted_results = sorted(combined_results.values(), key=lambda x: x[\"hybrid_score\"], reverse=True)[:top_k]\n",
    "    \n",
    "    return [result for result in sorted_results if result[\"hybrid_score\"] > 0.2]\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "    count = 0\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        # print(doc_id)\n",
    "        # try:\n",
    "        #     results = search_function(q)\n",
    "        #     count += 1\n",
    "        # except:\n",
    "        #     pass\n",
    "        results = search_function(q)\n",
    "        count += 1\n",
    "        # print(results)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        # print(relevance)\n",
    "        relevance_total.append(relevance)\n",
    "        # break\n",
    "\n",
    "    # print(count)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [05:29<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8880778588807786, 'mrr': 0.848337388483374}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: query_pinecone(q['question']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- {'hit_rate': 0.8880778588807786, 'mrr': 0.848337388483374}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all_documents: 166\n",
      "First 5 documents:\n",
      "['Biryani India Rice, chicken, saffron, spices, yogurt Layer rice with marinated chicken and spices, cook until fragrant. Main High 75 No Simmering Hot Layer partially cooked rice with marinated chicken, saffron, and spices, cook on low heat until rice is fully cooked and aromatic. 0af546e3-ef7f-4848-9d1d-b01f2c99553a', 'Stuffed Peppers Spain Bell peppers, rice, ground beef, tomatoes, spices Stuff peppers with rice and beef mixture, bake until peppers are tender. Main Medium 60 No Baking Hot Mix cooked rice with ground beef and tomatoes, stuff into hollowed bell peppers, bake until peppers are tender. 8276e8fd-3bc6-44ac-b6c6-ce78985c7099', 'Pasta Primavera Italy Pasta, tomatoes, zucchini, bell peppers, garlic Cook pasta with sautéed vegetables, serve with cheese. Main  20 Yes Boiling Hot Boil pasta until al dente, sauté tomatoes, zucchini, and bell peppers with garlic, toss with pasta and Parmesan. b305c0d9-8fc3-42a2-a90f-bb5efd40667a', 'Hainanese Chicken Rice Singapore Chicken, rice, ginger, garlic, chili sauce Boil chicken, cook rice with chicken broth, serve with chili sauce. Main  60 No Boiling Room Poach chicken, cook rice in the chicken broth, serve with ginger garlic paste and chili sauce. 726da803-6b23-470e-b469-5ff6a1a855f6', 'Chicken and Dumplings USA Chicken, flour, milk, butter, spices Simmer chicken in broth, add dumplings, cook until fluffy. Main  60 No Simmering Hot Cook chicken in a flavorful broth, drop spoonfuls of dough into simmering broth, cook until dumplings are fluffy. b6129a62-22bb-4f0d-ad6b-3d83189f340f']\n"
     ]
    }
   ],
   "source": [
    "all_documents = get_all_documents()\n",
    "print(f\"Length of all_documents: {len(all_documents)}\")\n",
    "print(\"First 5 documents:\")\n",
    "print(all_documents[:5])  # Print the first 5 documents to see their content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [04:57<00:00,  2.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.3746958637469586, 'mrr': 0.06387102016664079}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: hybrid_query_pinecone(q['question'], all_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks and make sure it is json parsable and nothing else is added\n",
    "to the below structure:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the recommended spice level for the Doro Wat dish?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the recommended spice level for the Doro Wat dish?\n",
      "Answer: The recommended spice level for the Doro Wat dish is High.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_dish_info(dish):\n",
    "    return \"\\n\".join([f\"{key}: {value}\" for key, value in dish['metadata'].items() if value])\n",
    "\n",
    "def query_openrouter(prompt):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.getenv('OPENROUTER_API_KEY')}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"meta-llama/llama-3.1-8b-instruct:free\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
    "    # print(response.json())\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "def qa_function(question):\n",
    "    # Query Pinecone\n",
    "    results = query_pinecone(question)\n",
    "    # print(results)\n",
    "    if not results:\n",
    "        return \"I'm sorry, I couldn't find any relevant information to answer your question.\"\n",
    "    \n",
    "    # Format the dish information\n",
    "    all_dish_info = \"\\n\\n\".join([format_dish_info(dish) for dish in results])\n",
    "\n",
    "    # print(all_dish_info)\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following information about a dish, please answer the question: {question}\n",
    "\n",
    "    Dish information:\n",
    "    {all_dish_info}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use OpenRouter to generate an answer\n",
    "    response = llm(prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def llm(prompt, model=\"llama-3.1-70b-versatile\"):\n",
    "\n",
    "    client = Groq(\n",
    "        api_key=GROQ_API_KEY\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # print(chat_completion.choices[0].message.content)\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Test the QA function\n",
    "question = ground_truth[0][\"question\"]\n",
    "answer = qa_function(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What is the recommended spice level for the Doro Wat dish?\n",
      "Generated Answer: The recommended spice level for the Doro Wat dish is High.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks and make sure it is json parsable and nothing else is added\n",
      "to the below structure:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>8276e8fd-3bc6-44ac-b6c6-ce78985c7099</td>\n",
       "      <td>How long does it take to cook Stuffed Peppers?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>f946cf79-a23e-413e-a1c1-75d859aefbcf</td>\n",
       "      <td>At what temperature should Dolma be served?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>865d6381-f4ad-4125-946f-6174e69032dc</td>\n",
       "      <td>What is the recommended temperature to serve S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ec101289-7120-4818-99ec-40345acf99b8</td>\n",
       "      <td>What is the recommended spice level for Tacos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>96cc1ca3-31d5-4c98-99ad-dcc6569a2191</td>\n",
       "      <td>What is the minimum amount of time I need to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>d69296f1-90b2-4c19-986c-5a67d1064f15</td>\n",
       "      <td>What type of main course is this recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>5435a146-92b5-4229-816d-b58ded66553e</td>\n",
       "      <td>Can you confirm the main cooking method for ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>47734007-2544-4d23-9deb-b57411a199db</td>\n",
       "      <td>What are the ingredients needed to make Saltim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>940feb4d-c0f8-4489-816a-f04342567840</td>\n",
       "      <td>At what temperature should Plov be served?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>a15f6dba-ad9d-442e-a111-bf9b3a9bd428</td>\n",
       "      <td>How long will it take to cook this dessert?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "528  8276e8fd-3bc6-44ac-b6c6-ce78985c7099   \n",
       "331  f946cf79-a23e-413e-a1c1-75d859aefbcf   \n",
       "735  865d6381-f4ad-4125-946f-6174e69032dc   \n",
       "17   ec101289-7120-4818-99ec-40345acf99b8   \n",
       "388  96cc1ca3-31d5-4c98-99ad-dcc6569a2191   \n",
       "..                                    ...   \n",
       "202  d69296f1-90b2-4c19-986c-5a67d1064f15   \n",
       "161  5435a146-92b5-4229-816d-b58ded66553e   \n",
       "752  47734007-2544-4d23-9deb-b57411a199db   \n",
       "375  940feb4d-c0f8-4489-816a-f04342567840   \n",
       "339  a15f6dba-ad9d-442e-a111-bf9b3a9bd428   \n",
       "\n",
       "                                              question  \n",
       "528     How long does it take to cook Stuffed Peppers?  \n",
       "331        At what temperature should Dolma be served?  \n",
       "735  What is the recommended temperature to serve S...  \n",
       "17      What is the recommended spice level for Tacos?  \n",
       "388  What is the minimum amount of time I need to c...  \n",
       "..                                                 ...  \n",
       "202            What type of main course is this recipe  \n",
       "161  Can you confirm the main cooking method for ma...  \n",
       "752  What are the ingredients needed to make Saltim...  \n",
       "375         At what temperature should Plov be served?  \n",
       "339        How long will it take to cook this dessert?  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [19:02<00:00,  5.71s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = qa_function(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    try:\n",
    "        evaluation = json.loads(evaluation)\n",
    "        evaluations.append((record, answer_llm, evaluation))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '8276e8fd-3bc6-44ac-b6c6-ce78985c7099',\n",
       "  'question': 'How long does it take to cook Stuffed Peppers?'},\n",
       " 'It takes 60 minutes to cook Stuffed Peppers.',\n",
       " {'Relevance': 'RELEVANT',\n",
       "  'Explanation': 'The generated answer directly addresses the question by providing a specific cooking time for Stuffed Peppers, making it a relevant response.'})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.809783\n",
       "PARTLY_RELEVANT    0.146739\n",
       "NON_RELEVANT       0.043478\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the recommended serving temperature fo...</td>\n",
       "      <td>The provided information does not include deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is the recommended spice level for this d...</td>\n",
       "      <td>Based on the information provided, the recomme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What is the recommended spice level for this d...</td>\n",
       "      <td>This query relates to one dish and as per that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>What is the spice level of Tzatziki dip?</td>\n",
       "      <td>The information provided about Tzatziki dip do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>What is the average time it takes to cook Onig...</td>\n",
       "      <td>Unfortunately, there is no information about O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Can I make Moussaka without cooking the eggpla...</td>\n",
       "      <td>To determine how uncooking or frying differs \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>What is the main cooking method used for this ...</td>\n",
       "      <td>The main cooking method used for this dessert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>What is the main cooking method used in this r...</td>\n",
       "      <td>There are multiple dishes in the information p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "20   What is the recommended serving temperature fo...   \n",
       "30   What is the recommended spice level for this d...   \n",
       "45   What is the recommended spice level for this d...   \n",
       "64            What is the spice level of Tzatziki dip?   \n",
       "122  What is the average time it takes to cook Onig...   \n",
       "137  Can I make Moussaka without cooking the eggpla...   \n",
       "159  What is the main cooking method used for this ...   \n",
       "172  What is the main cooking method used in this r...   \n",
       "\n",
       "                                                answer  \n",
       "20   The provided information does not include deta...  \n",
       "30   Based on the information provided, the recomme...  \n",
       "45   This query relates to one dish and as per that...  \n",
       "64   The information provided about Tzatziki dip do...  \n",
       "122  Unfortunately, there is no information about O...  \n",
       "137  To determine how uncooking or frying differs \\...  \n",
       "159  The main cooking method used for this dessert ...  \n",
       "172  There are multiple dishes in the information p...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval[\"relevance\"] == \"NON_RELEVANT\"][[\"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/rag-eval-llama-3.1-70b-versatile-groq.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
